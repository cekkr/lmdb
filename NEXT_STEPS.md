- Run a dedicated smoke-train and inspect the generated `var/eval_logs/*.json` file to baseline the new lexical / ROUGE / perplexity averages for future alerts (capture the summary in `studies/datasets.md`).
- Dry-run `scripts/migrate_sqlite_to_mariadb.py --apply --incremental` against the staging MariaDB instance to confirm upserts leave existing tables untouched before wiring it into the nightly job.
- Collect a multi-turn paraphraser regression set (include corrective turns) so the new guard rails can be re-verified automatically after future pipeline tweaks.
- Analyze first the dataset to train: in case of emotion_data.json, 128 limit of length is not enough to profile decently a response, and often the |RESPONSE| part is cut out.
- Use an external model to evaluate the quality of generated sentence as described in `studies/EvaluateSentenceQuality.md`: during training the quality profiling could be used to "re-train" worst results. 
- At the same time, using a synonymous reference (and a sentence embedding model) is important to evaluate the similarity of a sentence but its difference in the words: better to obtain a little different sentences in comparison, this mean that the model is "inventing" the grammar structure but not the concepts.
- Seen the length of responses of the emotion_data.json dataset, is important to ensure the right length evaluation and comparison with the original sample during training, or evaluation has no utility to improve the training performances a part for after-process profiling. This concept is important because there is no "learning rate" (a part the "randomness rate"), so it has to be adaptive.
- The migration from SQLite to MySQL is not clear: update the README.md to explain better the concept. Is SQLite used for better performance with little memory window during the training, and then during the inference is transposed totally to MySQL? The performances and configuration balance is not understandable.
- During training is it possible to adapt in real time to available CPU cores/threads with low usage to improve some elaborations speed? Excluding the saving/reading from database, that needs a precise lock order and it's important to avoid bottlenecks.